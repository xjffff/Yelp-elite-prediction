{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc31b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string, re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from spacy.lang.en import English, STOP_WORDS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363f67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop = STOP_WORDS\n",
    "punct = {p for p in string.punctuation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d5370",
   "metadata": {},
   "source": [
    "## 1.Load reviews and user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef8890b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('yelp_academic_dataset_review.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095204ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_json('yelp_academic_dataset_user.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bff75",
   "metadata": {},
   "source": [
    "## 2. Pharse reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81e1ba",
   "metadata": {},
   "source": [
    "features include:\\\n",
    "num of word\\\n",
    "num of sentences\\\n",
    "num of paragraphs\\\n",
    "num of letters\\\n",
    "if mentions pirce\\\n",
    "num of word in all caps\\\n",
    "num of exclamation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11c2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    try:\n",
    "        return text.decode('utf8')\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "def get_num_words(text):\n",
    "    return float(len(text.split()))\n",
    "\n",
    "def get_num_sents(text):\n",
    "    return text.count('. ') + text.count('! ') + text.count('? ') + text.count(') ') + \\\n",
    "            text.count('.\\n') + text.count('!\\n') + text.count('?\\n') + text.count(')\\n') + 1.0\n",
    "\n",
    "def get_num_para(text):\n",
    "    return text.count('\\n\\n') + 1.0\n",
    "\n",
    "def mentions_price(text):\n",
    "    return 1 if '$' in text else 0\n",
    "\n",
    "def get_allcaps(text):\n",
    "    text = re.sub(\"[^a-zA-z]\", \" \", text)\n",
    "    return len([word for word in text.split() if word.isupper() and len(word) > 2])\n",
    "\n",
    "def get_exclamations(text):\n",
    "    return text.count('!')\n",
    "\n",
    "def get_num_chars(text):\n",
    "    return float(len([char for char in text if char != ' ' and char not in punct]))\n",
    "\n",
    "def get_clean_tokens(text):  \n",
    "    \"\"\"Return tokens for each review; exclude stop words and lemmatize.\"\"\"\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    words = ' '.join(letters_only.lower().split())\n",
    "    tokens = [token.lemma_ for token in nlp(words)]\n",
    "    filtered = [t for t in tokens if t not in stop and t != '' and t != ' ' and t != '\\n' and t != '\\n\\n']\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def tokenize(df):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(len(df.text.values))):\n",
    "        tokens.append(get_clean_tokens(df.text.values[i]))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df69944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    # decode\n",
    "    df.loc[:, 'text'] = df.loc[:, 'text'].apply(decode)\n",
    "    \n",
    "    #get num of words in single review\n",
    "    df.loc[:, 'review_len_wrds'] = df.loc[:, 'text'].apply(get_num_words)\n",
    "    \n",
    "    #get num of sentences in single review\n",
    "    df.loc[:, 'review_len_sent'] = df.loc[:, 'text'].apply(get_num_sents)\n",
    "    \n",
    "    #get average number of words per sentence\n",
    "    df.loc[:, 'avg_wrd_in_sent'] = df.loc[:, 'review_len_wrds']/df.loc[:, 'review_len_sent']\n",
    "    \n",
    "    #get num of paragraphs\n",
    "    df.loc[:, 'num_para'] = df.loc[:, 'text'].apply(get_num_para)\n",
    "    \n",
    "    # check if price is mentioned\n",
    "    df.loc[:, 'mentions_price'] = df.loc[:, 'text'].apply(mentions_price)\n",
    "    \n",
    "    # get number of all caps words\n",
    "    df.loc[:, 'num_allcaps'] = df.loc[:, 'text'].apply(get_allcaps)\n",
    "    \n",
    "    # get number of exclamation marks\n",
    "    df.loc[:, 'num_exclamations'] = df.loc[:, 'text'].apply(get_exclamations)\n",
    "    \n",
    "    # get number of characters\n",
    "    df.loc[:,'num_chars'] = df.loc[:,'text'].apply(get_num_chars)\n",
    "    \n",
    "    # calculate ARI score (automatic readability index) for each review \n",
    "    df.loc[:,'ari_score'] = df.apply(\n",
    "        lambda row: 4.71 * (row.num_chars/float(row.review_len_wrds)) \\\n",
    "        + 0.5 * (row.review_len_wrds/float(row.review_len_sent)) - 21.43, \n",
    "        axis = 1)\n",
    "    \n",
    "    # get characters per word\n",
    "    df['avg_chars_per_word'] = df.loc[:,'num_chars'] / df.loc[:,'review_len_wrds']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9354dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2685066/2685066 [16:56:52<00:00, 44.01it/s]\n"
     ]
    }
   ],
   "source": [
    "clntkns = tokenize(df)\n",
    "df['tokens'] = clntkns\n",
    "get_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b06552",
   "metadata": {},
   "source": [
    "Lable each user by elite or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367509ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elite yes/no\n",
    "user['is_elite'] = user.elite.apply(lambda x: 1 if len(x) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afdffc25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>business_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>review_len_wrds</th>\n",
       "      <th>review_len_sent</th>\n",
       "      <th>avg_wrd_in_sent</th>\n",
       "      <th>num_para</th>\n",
       "      <th>mentions_price</th>\n",
       "      <th>num_allcaps</th>\n",
       "      <th>num_exclamations</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>avg_chars_per_word</th>\n",
       "      <th>is_elite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>PUFPaY9KxDAcGqfsorJp3Q</td>\n",
       "      <td>Ya85v4eqdd6k9Od8HbQjyA</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "      <td>review</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>mr hoagie institution walk like throwback year...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>7.128675</td>\n",
       "      <td>4.301205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>Iu6AxdBYGR4A0wspR9BYHA</td>\n",
       "      <td>KPvLNJ21_4wbYNctrOwWdQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "      <td>review</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>excellent food superb customer service I miss ...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>4.724638</td>\n",
       "      <td>4.739130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'funny': 1, 'useful': 1, 'cool': 0}</td>\n",
       "      <td>auESFwWvW42h6alXgFxAXQ</td>\n",
       "      <td>fFSoGV46Yxuwbr3fHNuZig</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>Yes this place is a little out dated and not o...</td>\n",
       "      <td>review</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>yes place little date open weekend staff pleas...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.138539</td>\n",
       "      <td>4.136986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>qiczib2fO_1VBG8IoCGvVg</td>\n",
       "      <td>pVMIt0a_QsKtuDfWVfSk2A</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>PROS: Italian hoagie was delicious.  Friendly ...</td>\n",
       "      <td>review</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>pro italian hoagie delicious friendly counter ...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2.629265</td>\n",
       "      <td>4.431373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'funny': 0, 'useful': 1, 'cool': 0}</td>\n",
       "      <td>qEE5EvV-f-s7yHC0Z4ydJQ</td>\n",
       "      <td>AEyiQ_Y44isJmNbMTyoMKQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>First the only reason this place could possibl...</td>\n",
       "      <td>review</td>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>reason place possibly win good hoagie s compet...</td>\n",
       "      <td>192.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>803.0</td>\n",
       "      <td>4.668594</td>\n",
       "      <td>4.182292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685061</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>kONznNes89LWlc1jcZtD0A</td>\n",
       "      <td>5-pv7M86ZdrXjfHPkPsZug</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>Still sick. Do not eat here unless you want to...</td>\n",
       "      <td>review</td>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>sick eat want puke brain hour later food look ...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.106961</td>\n",
       "      <td>3.794118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685062</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>6jXm3mrRGAPRENujxhlRpw</td>\n",
       "      <td>MjGrqy30haStX4Q6SWsdcg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>This place sucks especially the white manager ...</td>\n",
       "      <td>review</td>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>place suck especially white manager guy charge...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>21.538837</td>\n",
       "      <td>4.558140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685063</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>D8AR0UYdlHClqcjARPEr8Q</td>\n",
       "      <td>7ZfVeWubWTleBJUXXMPl_w</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-13</td>\n",
       "      <td>Not a bad stop for airport food. I got the chi...</td>\n",
       "      <td>review</td>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>bad stop airport food I chicken bowl filling s...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.224909</td>\n",
       "      <td>3.854545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685064</th>\n",
       "      <td>{'funny': 5, 'useful': 4, 'cool': 4}</td>\n",
       "      <td>nELVJlkX8T0mUAArSPSJxw</td>\n",
       "      <td>vwmqHxxmy9rEAwhbkLXmnQ</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>He stood in the face of a 2.5 star biz, and br...</td>\n",
       "      <td>review</td>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>stand face star biz brave salsarita s overpric...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>658.0</td>\n",
       "      <td>4.936538</td>\n",
       "      <td>4.217949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685065</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>maAimqEE4G483rtifPKlYg</td>\n",
       "      <td>DDmiTM_jMhshjYkXk5Sshg</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-11</td>\n",
       "      <td>2 pm Monday afternoon. Out of sour cream (ridi...</td>\n",
       "      <td>review</td>\n",
       "      <td>DH2Ujt_hwcMBIz8VvCb0Lg</td>\n",
       "      <td>pm monday afternoon sour cream ridiculous wait...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>191.0</td>\n",
       "      <td>4.515682</td>\n",
       "      <td>4.340909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2685066 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        votes                 user_id  \\\n",
       "0        {'funny': 0, 'useful': 0, 'cool': 0}  PUFPaY9KxDAcGqfsorJp3Q   \n",
       "1        {'funny': 0, 'useful': 0, 'cool': 0}  Iu6AxdBYGR4A0wspR9BYHA   \n",
       "2        {'funny': 1, 'useful': 1, 'cool': 0}  auESFwWvW42h6alXgFxAXQ   \n",
       "3        {'funny': 0, 'useful': 0, 'cool': 0}  qiczib2fO_1VBG8IoCGvVg   \n",
       "4        {'funny': 0, 'useful': 1, 'cool': 0}  qEE5EvV-f-s7yHC0Z4ydJQ   \n",
       "...                                       ...                     ...   \n",
       "2685061  {'funny': 0, 'useful': 0, 'cool': 0}  kONznNes89LWlc1jcZtD0A   \n",
       "2685062  {'funny': 0, 'useful': 0, 'cool': 0}  6jXm3mrRGAPRENujxhlRpw   \n",
       "2685063  {'funny': 0, 'useful': 0, 'cool': 0}  D8AR0UYdlHClqcjARPEr8Q   \n",
       "2685064  {'funny': 5, 'useful': 4, 'cool': 4}  nELVJlkX8T0mUAArSPSJxw   \n",
       "2685065  {'funny': 0, 'useful': 0, 'cool': 0}  maAimqEE4G483rtifPKlYg   \n",
       "\n",
       "                      review_id  stars       date  \\\n",
       "0        Ya85v4eqdd6k9Od8HbQjyA      4 2012-08-01   \n",
       "1        KPvLNJ21_4wbYNctrOwWdQ      5 2014-02-13   \n",
       "2        fFSoGV46Yxuwbr3fHNuZig      5 2015-10-31   \n",
       "3        pVMIt0a_QsKtuDfWVfSk2A      3 2015-12-26   \n",
       "4        AEyiQ_Y44isJmNbMTyoMKQ      2 2016-04-08   \n",
       "...                         ...    ...        ...   \n",
       "2685061  5-pv7M86ZdrXjfHPkPsZug      1 2015-11-23   \n",
       "2685062  MjGrqy30haStX4Q6SWsdcg      1 2015-11-24   \n",
       "2685063  7ZfVeWubWTleBJUXXMPl_w      3 2016-02-13   \n",
       "2685064  vwmqHxxmy9rEAwhbkLXmnQ      3 2016-04-30   \n",
       "2685065  DDmiTM_jMhshjYkXk5Sshg      1 2016-07-11   \n",
       "\n",
       "                                                      text    type  \\\n",
       "0        Mr Hoagie is an institution. Walking in, it do...  review   \n",
       "1        Excellent food. Superb customer service. I mis...  review   \n",
       "2        Yes this place is a little out dated and not o...  review   \n",
       "3        PROS: Italian hoagie was delicious.  Friendly ...  review   \n",
       "4        First the only reason this place could possibl...  review   \n",
       "...                                                    ...     ...   \n",
       "2685061  Still sick. Do not eat here unless you want to...  review   \n",
       "2685062  This place sucks especially the white manager ...  review   \n",
       "2685063  Not a bad stop for airport food. I got the chi...  review   \n",
       "2685064  He stood in the face of a 2.5 star biz, and br...  review   \n",
       "2685065  2 pm Monday afternoon. Out of sour cream (ridi...  review   \n",
       "\n",
       "                    business_id  \\\n",
       "0        5UmKMjUEUNdYWqANhGckJw   \n",
       "1        5UmKMjUEUNdYWqANhGckJw   \n",
       "2        5UmKMjUEUNdYWqANhGckJw   \n",
       "3        5UmKMjUEUNdYWqANhGckJw   \n",
       "4        5UmKMjUEUNdYWqANhGckJw   \n",
       "...                         ...   \n",
       "2685061  DH2Ujt_hwcMBIz8VvCb0Lg   \n",
       "2685062  DH2Ujt_hwcMBIz8VvCb0Lg   \n",
       "2685063  DH2Ujt_hwcMBIz8VvCb0Lg   \n",
       "2685064  DH2Ujt_hwcMBIz8VvCb0Lg   \n",
       "2685065  DH2Ujt_hwcMBIz8VvCb0Lg   \n",
       "\n",
       "                                                    tokens  review_len_wrds  \\\n",
       "0        mr hoagie institution walk like throwback year...             83.0   \n",
       "1        excellent food superb customer service I miss ...             23.0   \n",
       "2        yes place little date open weekend staff pleas...             73.0   \n",
       "3        pro italian hoagie delicious friendly counter ...             51.0   \n",
       "4        reason place possibly win good hoagie s compet...            192.0   \n",
       "...                                                    ...              ...   \n",
       "2685061  sick eat want puke brain hour later food look ...             34.0   \n",
       "2685062  place suck especially white manager guy charge...             43.0   \n",
       "2685063  bad stop airport food I chicken bowl filling s...             55.0   \n",
       "2685064  stand face star biz brave salsarita s overpric...            156.0   \n",
       "2685065  pm monday afternoon sour cream ridiculous wait...             44.0   \n",
       "\n",
       "         review_len_sent  avg_wrd_in_sent  num_para  mentions_price  \\\n",
       "0                    5.0        16.600000       1.0               0   \n",
       "1                    3.0         7.666667       1.0               0   \n",
       "2                    6.0        12.166667       1.0               0   \n",
       "3                    8.0         6.375000       3.0               0   \n",
       "4                   15.0        12.800000       6.0               1   \n",
       "...                  ...              ...       ...             ...   \n",
       "2685061              3.0        11.333333       1.0               0   \n",
       "2685062              1.0        43.000000       1.0               0   \n",
       "2685063              5.0        11.000000       1.0               0   \n",
       "2685064             12.0        13.000000       4.0               1   \n",
       "2685065              4.0        11.000000       1.0               0   \n",
       "\n",
       "         num_allcaps  num_exclamations  num_chars  ari_score  \\\n",
       "0                  0                 0      357.0   7.128675   \n",
       "1                  0                 0      109.0   4.724638   \n",
       "2                  0                 0      302.0   4.138539   \n",
       "3                  7                 0      226.0   2.629265   \n",
       "4                  1                 2      803.0   4.668594   \n",
       "...              ...               ...        ...        ...   \n",
       "2685061            0                 0      129.0   2.106961   \n",
       "2685062            0                 0      196.0  21.538837   \n",
       "2685063            0                 0      212.0   2.224909   \n",
       "2685064            0                 1      658.0   4.936538   \n",
       "2685065            0                 2      191.0   4.515682   \n",
       "\n",
       "         avg_chars_per_word  is_elite  \n",
       "0                  4.301205         0  \n",
       "1                  4.739130         0  \n",
       "2                  4.136986         0  \n",
       "3                  4.431373         0  \n",
       "4                  4.182292         0  \n",
       "...                     ...       ...  \n",
       "2685061            3.794118         0  \n",
       "2685062            4.558140         0  \n",
       "2685063            3.854545         0  \n",
       "2685064            4.217949         1  \n",
       "2685065            4.340909         0  \n",
       "\n",
       "[2685066 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ab39c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.set_index('user_id', inplace = True)\n",
    "df['is_elite'] = df.user_id.apply(lambda x: user.loc[x, 'is_elite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66a9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = .25)\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None, \\\n",
    "                             max_features = 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "882722cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_reviews = train[train.is_elite == 1]\n",
    "nonelite_reviews = train[train.is_elite == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d350db",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_features = vectorizer.fit_transform(elite_reviews.tokens)\n",
    "elite_words = vectorizer.get_feature_names_out()\n",
    "elite_features = elite_features.toarray()\n",
    "elite_dist = np.sum(elite_features, axis = 0)\n",
    "elite_sorted = sorted(zip(elite_words, elite_dist), key = lambda x: x[1], reverse = True)\n",
    "elite_wrds_dict = dict(elite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a28e0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonelite_features = vectorizer.fit_transform(nonelite_reviews.tokens)\n",
    "nonelite_words = vectorizer.get_feature_names_out()\n",
    "nonelite_features = nonelite_features.toarray()\n",
    "nonelite_dist = np.sum(nonelite_features, axis = 0)\n",
    "nonelite_sorted = sorted(zip(nonelite_words, nonelite_dist), key = lambda x: x[1], reverse = True)\n",
    "nonelite_wrds_dict = dict(nonelite_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4e3ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique words (not present in intersection)\n",
    "onlyelite_words = {\n",
    "    word : elite_wrds_dict[word] \n",
    "    for word in elite_wrds_dict \n",
    "    if word not in nonelite_wrds_dict}\n",
    "\n",
    "onlynonelite_words = {\n",
    "    word : nonelite_wrds_dict[word] \n",
    "    for word in nonelite_wrds_dict \n",
    "    if word not in elite_wrds_dict}\n",
    "elite_top50 = sorted(onlyelite_words.items(), key = lambda x: x[1], reverse = True)[:50]\n",
    "ne_top50 = sorted(onlynonelite_words.items(), key = lambda x: x[1], reverse = True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8567380b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Mismatch between array dtype ('<U21') and format specifier ('%.18e,%.18e')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\npyio.py:1565\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1565\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m newline\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not numpy.str_",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(elite_top50)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43melite_top50.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\npyio.py:1567\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1565\u001b[0m             v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtuple\u001b[39m(row) \u001b[38;5;241m+\u001b[39m newline\n\u001b[0;32m   1566\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1567\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between array dtype (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1568\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat specifier (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m                             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mstr\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;28mformat\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1570\u001b[0m         fh\u001b[38;5;241m.\u001b[39mwrite(v)\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(footer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Mismatch between array dtype ('<U21') and format specifier ('%.18e,%.18e')"
     ]
    }
   ],
   "source": [
    "a = np.array(elite_top50)\n",
    "np.savetxt(\"elite_top50.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a28e6882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['de', '30347'],\n",
       "       ['la', '23394'],\n",
       "       ['locate', '21937'],\n",
       "       ['space', '21215'],\n",
       "       ['tomato', '19821'],\n",
       "       ['crispy', '19242'],\n",
       "       ['butter', '17795'],\n",
       "       ['mix', '17705'],\n",
       "       ['le', '17427'],\n",
       "       ['city', '17035'],\n",
       "       ['pepper', '16975'],\n",
       "       ['brunch', '16704'],\n",
       "       ['grab', '16390'],\n",
       "       ['et', '16328'],\n",
       "       ['tender', '16159'],\n",
       "       ['seating', '16155'],\n",
       "       ['mushroom', '15777'],\n",
       "       ['soft', '15620'],\n",
       "       ['sound', '15494'],\n",
       "       ['toast', '15456'],\n",
       "       ['standard', '15293'],\n",
       "       ['note', '15247'],\n",
       "       ['mall', '15205'],\n",
       "       ['black', '15016'],\n",
       "       ['dance', '14989'],\n",
       "       ['salmon', '14783'],\n",
       "       ['ton', '14730'],\n",
       "       ['center', '14722'],\n",
       "       ['flavorful', '14711'],\n",
       "       ['cute', '14648'],\n",
       "       ['event', '14544'],\n",
       "       ['seafood', '14468'],\n",
       "       ['interesting', '14385'],\n",
       "       ['lobster', '14315'],\n",
       "       ['pour', '14249'],\n",
       "       ['cafe', '14148'],\n",
       "       ['sausage', '14080'],\n",
       "       ['smoke', '13794'],\n",
       "       ['section', '13758'],\n",
       "       ['level', '13711'],\n",
       "       ['fruit', '13668'],\n",
       "       ['unique', '13560'],\n",
       "       ['idea', '13505'],\n",
       "       ['crust', '13417'],\n",
       "       ['hang', '13368'],\n",
       "       ['pie', '13317'],\n",
       "       ['un', '13256'],\n",
       "       ['topping', '13238'],\n",
       "       ['wrap', '13197'],\n",
       "       ['spice', '13182']], dtype='<U21')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99a1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9170f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hair', '62560'],\n",
       "       ['company', '54726'],\n",
       "       ['phone', '54234'],\n",
       "       ['nail', '51605'],\n",
       "       ['receive', '49894'],\n",
       "       ['rude', '47274'],\n",
       "       ['professional', '47112'],\n",
       "       ['fix', '46332'],\n",
       "       ['appointment', '43114'],\n",
       "       ['horrible', '42363'],\n",
       "       ['dr', '42285'],\n",
       "       ['office', '41020'],\n",
       "       ['min', '41015'],\n",
       "       ['speak', '38091'],\n",
       "       ['explain', '38066'],\n",
       "       ['terrible', '35512'],\n",
       "       ['question', '35463'],\n",
       "       ['send', '34376'],\n",
       "       ['twice', '34182'],\n",
       "       ['understand', '33984'],\n",
       "       ['purchase', '33961'],\n",
       "       ['salon', '33890'],\n",
       "       ['completely', '32042'],\n",
       "       ['provide', '31132'],\n",
       "       ['massage', '30706'],\n",
       "       ['break', '30533'],\n",
       "       ['greet', '29674'],\n",
       "       ['answer', '28834'],\n",
       "       ['save', '28628'],\n",
       "       ['product', '28389'],\n",
       "       ['desk', '28346'],\n",
       "       ['deliver', '28142'],\n",
       "       ['class', '28012'],\n",
       "       ['die', '27976'],\n",
       "       ['complaint', '27725'],\n",
       "       ['boyfriend', '27622'],\n",
       "       ['woman', '27576'],\n",
       "       ['daughter', '27531'],\n",
       "       ['poor', '27068'],\n",
       "       ['dollar', '27039'],\n",
       "       ['disappointed', '27025'],\n",
       "       ['state', '26990'],\n",
       "       ['color', '26671'],\n",
       "       ['son', '26575'],\n",
       "       ['request', '26498'],\n",
       "       ['number', '26281'],\n",
       "       ['guest', '26271'],\n",
       "       ['pleasant', '25873'],\n",
       "       ['authentic', '25663'],\n",
       "       ['immediately', '25355']], dtype='<U21')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(ne_top50)\n",
    "numpy.savetxt(\"ne_top50.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb9b00cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_words_list = elite_words.tolist()\n",
    "nonelite_words_list = nonelite_words.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81be6b",
   "metadata": {},
   "source": [
    "## 5. Export data for use in classification notebook and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b07b3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elite_words(tokens):\n",
    "    try:\n",
    "        tokens = tokens.split()\n",
    "        return len(set(elite_words_list).intersection(tokens))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_nonelite_words(tokens):\n",
    "    try:\n",
    "        tokens = tokens.split()\n",
    "        return len(set(nonelite_words_list).intersection(tokens))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def add_content_counts(df):\n",
    "    df['num_elite_words'] = df.text.apply(get_elite_words)\n",
    "    df['num_ne_words'] = df.text.apply(get_nonelite_words)\n",
    "\n",
    "add_content_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb624fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\47965\\AppData\\Local\\Temp\\ipykernel_13940\\775572352.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_avgs = byuser.mean().loc[:, 'review_len_wrds':]\n"
     ]
    }
   ],
   "source": [
    "byuser = df.groupby('user_id')\n",
    "user_avgs = byuser.mean().loc[:, 'review_len_wrds':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a998276c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_len_wrds</th>\n",
       "      <th>review_len_sent</th>\n",
       "      <th>avg_wrd_in_sent</th>\n",
       "      <th>num_para</th>\n",
       "      <th>mentions_price</th>\n",
       "      <th>num_allcaps</th>\n",
       "      <th>num_exclamations</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>ari_score</th>\n",
       "      <th>avg_chars_per_word</th>\n",
       "      <th>is_elite</th>\n",
       "      <th>num_elite_words</th>\n",
       "      <th>num_ne_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>---teJGnwK07UO6_oJfbRw</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--0HEXd4W6bJI8k7E0RxTA</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>4.702750</td>\n",
       "      <td>4.858333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--0KsjlAThNWua2Pr4HStQ</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>14.477183</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>548.166667</td>\n",
       "      <td>5.596217</td>\n",
       "      <td>4.201194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--0mI_q_0D1CdU4P_hoImQ</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.581310</td>\n",
       "      <td>4.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--106arHH4D3fLenTl3YZA</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>4.644674</td>\n",
       "      <td>4.315217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzx_41wDUNxpcgrdOtERvw</th>\n",
       "      <td>79.923077</td>\n",
       "      <td>6.538462</td>\n",
       "      <td>11.890354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>357.538462</td>\n",
       "      <td>5.805732</td>\n",
       "      <td>4.520288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.461538</td>\n",
       "      <td>11.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzyeArRv6I5HpEJlOCOPAQ</th>\n",
       "      <td>206.666667</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>822.000000</td>\n",
       "      <td>7.421741</td>\n",
       "      <td>4.061469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzyoUJV5QTUEuuVoICcdYQ</th>\n",
       "      <td>74.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>317.500000</td>\n",
       "      <td>5.163643</td>\n",
       "      <td>4.151163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzytqT9s0WS-d4WgLYmLoA</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>710.000000</td>\n",
       "      <td>4.468770</td>\n",
       "      <td>3.879781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzfn8ETe8A4kp4HnTK86g</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.385145</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686556 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        review_len_wrds  review_len_sent  avg_wrd_in_sent  \\\n",
       "user_id                                                                     \n",
       "---teJGnwK07UO6_oJfbRw        36.000000         5.000000         7.200000   \n",
       "--0HEXd4W6bJI8k7E0RxTA        19.000000         3.500000         6.500000   \n",
       "--0KsjlAThNWua2Pr4HStQ       128.000000         8.333333        14.477183   \n",
       "--0mI_q_0D1CdU4P_hoImQ        28.000000         3.000000         9.333333   \n",
       "--106arHH4D3fLenTl3YZA        92.000000         8.000000        11.500000   \n",
       "...                                 ...              ...              ...   \n",
       "zzx_41wDUNxpcgrdOtERvw        79.923077         6.538462        11.890354   \n",
       "zzyeArRv6I5HpEJlOCOPAQ       206.666667        11.000000        19.444444   \n",
       "zzyoUJV5QTUEuuVoICcdYQ        74.500000         4.500000        14.083333   \n",
       "zzytqT9s0WS-d4WgLYmLoA       183.000000        12.000000        15.250000   \n",
       "zzzfn8ETe8A4kp4HnTK86g        22.000000         2.500000         9.083333   \n",
       "\n",
       "                        num_para  mentions_price  num_allcaps  \\\n",
       "user_id                                                         \n",
       "---teJGnwK07UO6_oJfbRw  1.000000        0.000000     0.000000   \n",
       "--0HEXd4W6bJI8k7E0RxTA  1.000000        0.000000     0.000000   \n",
       "--0KsjlAThNWua2Pr4HStQ  3.833333        0.000000     0.500000   \n",
       "--0mI_q_0D1CdU4P_hoImQ  1.000000        0.000000     0.000000   \n",
       "--106arHH4D3fLenTl3YZA  2.000000        0.000000     0.000000   \n",
       "...                          ...             ...          ...   \n",
       "zzx_41wDUNxpcgrdOtERvw  1.000000        0.153846     0.000000   \n",
       "zzyeArRv6I5HpEJlOCOPAQ  1.666667        0.666667     5.333333   \n",
       "zzyoUJV5QTUEuuVoICcdYQ  1.000000        0.000000     0.000000   \n",
       "zzytqT9s0WS-d4WgLYmLoA  2.000000        0.000000     0.000000   \n",
       "zzzfn8ETe8A4kp4HnTK86g  1.000000        0.000000     0.000000   \n",
       "\n",
       "                        num_exclamations   num_chars  ari_score  \\\n",
       "user_id                                                           \n",
       "---teJGnwK07UO6_oJfbRw          0.000000  153.000000   2.187500   \n",
       "--0HEXd4W6bJI8k7E0RxTA          0.000000   92.500000   4.702750   \n",
       "--0KsjlAThNWua2Pr4HStQ          0.166667  548.166667   5.596217   \n",
       "--0mI_q_0D1CdU4P_hoImQ          4.000000  115.000000   2.581310   \n",
       "--106arHH4D3fLenTl3YZA          0.000000  397.000000   4.644674   \n",
       "...                                  ...         ...        ...   \n",
       "zzx_41wDUNxpcgrdOtERvw          0.692308  357.538462   5.805732   \n",
       "zzyeArRv6I5HpEJlOCOPAQ          6.666667  822.000000   7.421741   \n",
       "zzyoUJV5QTUEuuVoICcdYQ          0.000000  317.500000   5.163643   \n",
       "zzytqT9s0WS-d4WgLYmLoA          1.000000  710.000000   4.468770   \n",
       "zzzfn8ETe8A4kp4HnTK86g          0.000000   95.000000   3.385145   \n",
       "\n",
       "                        avg_chars_per_word  is_elite  num_elite_words  \\\n",
       "user_id                                                                 \n",
       "---teJGnwK07UO6_oJfbRw            4.250000       0.0         4.000000   \n",
       "--0HEXd4W6bJI8k7E0RxTA            4.858333       0.0         3.500000   \n",
       "--0KsjlAThNWua2Pr4HStQ            4.201194       1.0        17.500000   \n",
       "--0mI_q_0D1CdU4P_hoImQ            4.107143       0.0         4.000000   \n",
       "--106arHH4D3fLenTl3YZA            4.315217       0.0        11.000000   \n",
       "...                                    ...       ...              ...   \n",
       "zzx_41wDUNxpcgrdOtERvw            4.520288       0.0        10.461538   \n",
       "zzyeArRv6I5HpEJlOCOPAQ            4.061469       0.0        17.000000   \n",
       "zzyoUJV5QTUEuuVoICcdYQ            4.151163       0.0         7.000000   \n",
       "zzytqT9s0WS-d4WgLYmLoA            3.879781       0.0        16.000000   \n",
       "zzzfn8ETe8A4kp4HnTK86g            4.304348       0.0         3.000000   \n",
       "\n",
       "                        num_ne_words  \n",
       "user_id                               \n",
       "---teJGnwK07UO6_oJfbRw      4.000000  \n",
       "--0HEXd4W6bJI8k7E0RxTA      3.500000  \n",
       "--0KsjlAThNWua2Pr4HStQ     18.000000  \n",
       "--0mI_q_0D1CdU4P_hoImQ      3.000000  \n",
       "--106arHH4D3fLenTl3YZA     11.000000  \n",
       "...                              ...  \n",
       "zzx_41wDUNxpcgrdOtERvw     11.153846  \n",
       "zzyeArRv6I5HpEJlOCOPAQ     18.333333  \n",
       "zzyoUJV5QTUEuuVoICcdYQ      8.500000  \n",
       "zzytqT9s0WS-d4WgLYmLoA     17.000000  \n",
       "zzzfn8ETe8A4kp4HnTK86g      3.500000  \n",
       "\n",
       "[686556 rows x 13 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8555593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avgs.to_pickle('pickled/user_avgs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16bad46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('pickled/all_text_feat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeabe82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.10 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
